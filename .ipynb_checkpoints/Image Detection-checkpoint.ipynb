{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4825eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6adb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422af7d",
   "metadata": {},
   "source": [
    "# Read image into binary matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc1eee",
   "metadata": {},
   "source": [
    "## Understand DFS and why using DFS in this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7beb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(image):\n",
    "    # Create a copy of the input image\n",
    "    labeled_image = np.zeros_like(image)\n",
    "    label = 1  # Start labeling from 1\n",
    "\n",
    "    # Define 8-connectivity\n",
    "    connectivity = 8\n",
    "\n",
    "    # Iterate through each pixel in the image\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            # If the pixel is a foreground pixel and not labeled yet\n",
    "            if image[y, x] != 0 and labeled_image[y, x] == 0:\n",
    "                # Perform Depth-First Search (DFS) to label connected component\n",
    "                stack = [(y, x)]\n",
    "                while stack:\n",
    "                    # Pop the pixel from the stack\n",
    "                    current_y, current_x = stack.pop()\n",
    "                    labeled_image[current_y, current_x] = label\n",
    "\n",
    "                    # Check 8-connectivity neighbors\n",
    "                    for dy in range(-1, 2):\n",
    "                        for dx in range(-1, 2):\n",
    "                            # Skip the central pixel\n",
    "                            if dy == 0 and dx == 0:\n",
    "                                continue\n",
    "                            # Neighbor coordinates\n",
    "                            ny, nx = current_y + dy, current_x + dx\n",
    "                            # Check bounds and if neighbor is foreground and not labeled\n",
    "                            if 0 <= ny < image.shape[0] and 0 <= nx < image.shape[1] and \\\n",
    "                                    image[ny, nx] != 0 and labeled_image[ny, nx] == 0:\n",
    "                                stack.append((ny, nx))\n",
    "\n",
    "                # Increment label for the next connected component\n",
    "                label += 1\n",
    "\n",
    "    return labeled_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e252332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('test_image/STOP SIGN (5).jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply simple thresholding\n",
    "_, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "# Find connected components\n",
    "num_labels, labels = cv2.connectedComponents(binary_image)\n",
    "\n",
    "# Create a random color map for each label\n",
    "colors = np.random.randint(0, 255, size=(num_labels, 3), dtype=np.uint8)\n",
    "colors[0] = [0, 0, 0]  # Set background label to black\n",
    "\n",
    "# Create an output image with colored labels\n",
    "colored_labels = colors[labels]\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Connected Components', colored_labels)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a469ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1847\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # First Convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        # Second Convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout2d(p=0.25)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Adjusted input size after max pooling\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer with 10 classes (assuming it's a classification task)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional layer followed by ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Second Convolutional layer followed by ReLU activation\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Max pooling layer\n",
    "        x = self.pool(x)\n",
    "        # Dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(-1, 64 * 12 * 12)\n",
    "        # First fully connected layer followed by ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Dropout layer\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Output layer with softmax activation\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)  # Applying softmax activation on output\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = MyCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c24a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
